<!DOCTYPE html>
<html>
<head>

<title> How MapReduce Works</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<script type="text/javascript" src="../../js/jquery-1.6.4.min.js"></script>

<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shCore.css">
<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shThemeRDark.css">
<script type="text/javascript" src="../../js/sh/scripts/shCore.js"></script>
<script type="text/javascript" src="../../js/sh/scripts/shAutoloader.js"></script>

<script type="text/javascript" src="../../js/main.js"></script>
<script type="text/javascript" src="../../js/ASCIIMathML.js"></script>

<link rel="Stylesheet" type="text/css" href="../../style.css">
<link rel="Stylesheet" type="text/css" href="../../css/main.css">

</head>
<body>
	<div class="hidden">
		<input id="root_path" type="text" value="../../">
	</div>
	<div id="body-wrapper">
		<div id="container">
			<div id="top">
				<div id="page-title">
					<a href="../../index.html">烂笔头</a>
				</div>
				<ul id="top-nav">
				</ul>
			</div>
			<div id="middle">
				
<div class="toc">
<ul>
<li><a href="#toc_1">How MapReduce Works</a>
<ul>
<li><a href="#toc_1.1">MapReduce工作机制</a>
<ul>
<li><a href="#toc_1.1.1">经典的MapReduce(MapReduce 1)</a>
<li><a href="#toc_1.1.2">二代:Yarn(MapReduce 2)</a>
</ul>
<li><a href="#toc_1.2">处理失败</a>
<ul>
<li><a href="#toc_1.2.1">经典MapReduce(MapReduce 1)的失败</a>
<li><a href="#toc_1.2.2">YARN(MapReduce 2)中的失败</a>
</ul>
<li><a href="#toc_1.3">Job的调度</a>
<li><a href="#toc_1.4">Shuffle和排序</a>
<li><a href="#toc_1.5">Task的运行</a>
</ul>
</ul>
</div>


<p>
当前日期: 01/30/2013 Wed 
</p>
<h1 id="toc_1">How MapReduce Works</h1>

<h2 id="toc_1.1">MapReduce工作机制</h2>

<h3 id="toc_1.1.1">经典的MapReduce(MapReduce 1)</h3>
<p>
<img src="mapreduce_classic.png" />
</p>

<p>
<strong>参与者:</strong>
</p>
<ul>
<li>
<strong>Client:</strong>, MapReduce Job的提交者

<li>
<strong>Jobtracker:</strong>, 负责安排Job的运行，对应的 class 是 JobTracker.

<li>
<strong>Tasktrackers:</strong> 负责运行由Job分解出的Task, 对应的 class 是 TaskTracker.

<li>
<strong>Distributed Filesystem:</strong> 通常HDFS,用于共享Job相关的文件

</ul>

<p>
<strong>提交Job:</strong>
</p>
<ol>
<li>
<strong>Step 1:</strong> 创建一个JobSubmitter实例，并调用其方法submitJobInternal(). (由Job的方法submit()触发)

<li>
方法<code>waitForCompletion()</code>会每秒拉一次Job的状态与进度

<li>
提交的具体步骤：

<ol>
<li>
<strong>Step 2:</strong> 向jobtracker请求一个新的job ID (<code>getNewJobId()</code>)

<li>
查看job的输出设置条件是否满足，比如输出文件夹是否存在，不存在不能运行

<li>
计算输入的分片，不能分片不能运行，比如输入路径不存在

<li>
<strong>Step 3:</strong> 拷贝job的相关资源到jobtracker的文件系统（jar,configuration,分片结果等），jar文件会有很多份

<ul>
<li>
通过属性 <code>mapred.submit.replication</code> 指定，默认为10

<li>
当运行Task时，可以很快速从集群中获得

</ul>
<li>
<strong>Step 4:</strong> 告诉Jobtracker,job已准备好运行（调用JobTracker的submitJob() ).

</ol>
</ol>

<p>
<strong>初始化Job:</strong>
</p>
<ol>
<li>
Jobtracker收到submitJob()的请求后，会把job放入一个队列里

<li>
job scheduler会从队列里取出并初始化

<li>
<strong>Step 5:</strong> 创建一个代表job的对象

<ul>
<li>
包含task信息

<li>
进度和状态信息

</ul>
<li>
<strong>Step 6:</strong> 接受由client计算出的分片信息，创建要运行的task列表

<ul>
<li>
为每一个分片创建一个map task

<li>
属性 <code>mapred.reduce.tasks</code> 确定reduce task的数目

<li>
此时所有的task都会被分配id

<li>
还有两个额外的task会被创建：job setup task 和 job clean up task

<ul>
<li>
用于在任何map　task前启动一个job

<li>
用于在所有reduce task后，清理工作

</ul>
</ul>
</ol>

<p>
<strong>分配Task:</strong>
</p>
<ol>
<li>
<strong>Step 7:</strong> task tracker 会不间隔向job tracker发送心跳heart beat(使用一个循环体）

<ul>
<li>
告诉job tracker,它还活着

<li>
也可以用于交换信息

<li>
比如告诉job　tracker,已经准备好接收新的task, job tracker 就会分配给它一个新的任务

</ul>
<li>
task tracker 会有一定数量的map task和reduce task的槽位

<ul>
<li>
这两种槽位是相互独立的

<li>
具体的数量由cpu 核数和内存决定

<li>
task tracker 会优先使用map task的槽位

</ul>
<li>
对于reduce task, job tracker只是简单的取出运行

<li>
对于map task, job tracker会尽量选取距数据最近的task tracker运行，最好在同一个data node 上

</ol>

<p>
<strong>运行Task:</strong>
</p>
<ol>
<li>
task tracker 分配到一个task, 接下来就是运行这个task

<li>
<strong>Step 8:</strong> 接收所需的文件

<ol>
<li>
将job jar和所需要的一切文件拷到本地系统

<li>
为task创建一个本地目录，并将jar解压

<li>
创建一个　TaskRunner 实例，用于运行task

</ol>
<li>
<strong>Step 9:</strong> 启动一个新的JVM

<li>
<strong>Step 10:</strong> 运行task

<li>
子进程会每隔几秒钟向父进程回报一下task进度，直到task完成

<li>
每一个task都会运行setup和cleanup操作

</ol>

<p>
<strong>进度与状态报告:</strong>
</p>
<ol>
<li>
当一个task运行时，会记录它的进度

<li>
当task进度发生变化时，会设置一个flag,表明需要向task tracker汇报进度

<li>
有一个独立线程会每隔３s检查一个这个flag,如果需要就通知task tracker当前的进度

<li>
task tracker会每５s向job tracker发送一个心跳，如果有信息会随着一起发送

<li>
client的job每秒向job tracker拉一次状态

</ol>
<p>
<img src="mapreduce_classic_progress.png" />
</p>

<p>
<strong>Job完成:</strong>
</p>
<ol>
<li>
job tracker收到最后一个task的完成通知后(cleanup task)

<li>
将job设为成功

<li>
属性 <code>job.end.notification.url</code> 可以配置一个需要http通知的url

</ol>

<h3 id="toc_1.1.2">二代:Yarn(MapReduce 2)</h3>
<p>
在4000个结点以上的集群中，上述方案的水平扩展就会遇到瓶颈，所以有了YARN:
</p>
<ul>
<li>
Yet Another Resource Negotiator

<li>
YARN Application Resource Negotiator

</ul>

<ol>
<li>
YARN通过分解Jobtracker的工作来达到扩大水平扩展能力的手段。jobtracker 的两项职责：

<ol>
<li>
job scheduling 分配task给tasktracker

<li>
监视task的执行进度

</ol>
<li>
YARN将这两项职责分给两个独立的后台进程：

<ul>
<li>
<strong>Resource Manager:</strong> 管理集群上资源的使用

<li>
<strong>Application Master:</strong> 管理运行于集群上的application的生命周期，application对应job 

</ul>
</ol>
  
<p>
<strong>基本思路:</strong>
</p>
<ol>
<li>
此处的application就是mapreduce job

<li>
<code>application master</code> 与 <code>resource manager</code> 协商集群上的资源

<li>
资源表现为容器 <code>containers</code> , 它有一定的内存限制

<li>
application的进程就运行于这些 <code>containers</code> 上

<li>
这些 <code>containers</code> 会被运行于集群结点上的  <code>node manager</code> 监管，避免application使用超过分配给它的资源

<li>
目前集群上的资源就是内存

</ol>

<p>
<strong>与jobtracker相比，每一个application拥有自己的</strong> <code>application master</code> , <strong>运行于application的期间，application就是mapreduce job</strong>
</p>
  
<p>
<img src="mapreduce_yarn.png" />
</p>

<p>
<strong>参与者:</strong>
</p>
<ul>
<li>
<strong>Client:</strong>, MapReduce Job的提交者

<li>
<strong>YARN resource manager:</strong> 管理协调集群上的计算资源

<li>
<strong>YARN node managers:</strong>  启动并监视其所在结点上的计算容器

<li>
<strong>MapReduce application master:</strong> 管理协调一个mapreduce job的所有task. application master 和 job的 task运行于由 <code>resource manager</code> 调度安排并由 <code>node manager</code> 管理的计算容器中

<li>
<strong>Distributed Filesystem:</strong> 通常HDFS,用于共享Job相关的文件

</ul>
 
<p>
<strong>提交Job:</strong>
</p>
<ol>
<li>
<strong>Step 1:</strong> 创建一个JobSubmitter实例，并调用其方法submitJobInternal(). (由Job的方法submit()触发)

<ul>
<li>
和MapReduce 1使用一样的api

<li>
通过属性 <code>mapreduce.framework.name</code> 设置为yarn激活YARN

</ul>
<li>
<strong>Step 2:</strong> 从 <code>resource manager</code> 获取一个新的application id

<li>
client 计算分片

<ul>
<li>
分片也可以在集群中计算

<li>
通过属性 <code>yarn.app.mapreduce.am.compute-splits-in-cluster</code> 激活

</ul>
<li>
<strong>Step 3:</strong> 拷贝application的相关资源到HDFS（jar,configuration,分片结果等），jar文件会有很多份

<li>
<strong>Step 4:</strong> 在 <code>resource manager</code> 调用 submitApplication() 提交一个application

</ol>

<p>
<strong>初始化Job:</strong>
</p>
<ol>
<li>
<strong>Step 5a:</strong> scheduler 分配一个 <code>container</code>

<li>
<strong>Step 5b:</strong> <code>resource manager</code> 在这个 <code>container</code> 上运行 <code>application master</code>, 并在 <code>node manager</code> 的管理下

<li>
<strong>Step 6:</strong> <code>applicaiton master</code> 初始化一个application

<ul>
<li>
<code>applicaiton master</code> 对应类  MRAppMaster

<li>
创建一系列对象追踪job的进度 

<li>
稍后它会从task处得到进度和完成信息

</ul>
<li>
<strong>Step 7:</strong> <code>applicaiton master</code> 从分布式系统中获取计算好的splits

<li>
 <code>application master</code> 创建tasks:

<ul>
<li>
为每一个split创建一个map task

<li>
创建redeuce task, 数量由属性 <code>mapreduce.job.reduces</code> 指定

</ul>
<li>
 如果是一个小的job,<code>application master</code> 将会在它自身的jvm上运行些task,如果判定这是一个小的job :

<ul>
<li>
<code>mapreduce.job.ubertask.maxmaps</code> 默认值10

<li>
<code>mapreduce.job.ubertask.maxreduces</code> 默认值1

<li>
<code>mapreduce.job.ubertask.maxbytes</code> 默认值HDFS Block

<li>
<code>mapreduce.job.ubertask.enable</code> 默认值true

</ul>
</ol>

<p>
<strong>分配Task:</strong>
</p>
<ol>
<li>
<strong>Step 7:</strong> <code>applicaiton master</code> 向 <code>resource manager</code> 申请运行map task和reduce task所需的资源 <code>containers</code>

<li>
为task分配内存,通过下列属性来指定

<ul>
<li>
<code>mapreduce.map.memory.mb</code> map task的内存  默认:1024M

<li>
<code>mapreduce.reduce.memory.mb</code> reduce task的内存   默认:1024M

<li>
<code>yarn.scheduler.capacity.minimum-allocation-mb</code> 最小值限制，默认为1G

<li>
<code>yarn.scheduler.capacity.maximum-allocation-mb</code>  最大值限制，默认为10G

<li>
分配给task的内存必须在最小值和最大值之间，且是最小值的整数倍

<li>
如果不是整数倍，会自动上升为整数倍

</ul>
</ol>

<p>
<strong>运行Task:</strong>
</p>
<ol>
<li>
task被分配了一个资源 <code>container</code> 

<li>
<strong>Step 9a:</strong> <code>application master</code> 通知相应的 <code>node manager</code> 运行这个 <code>container</code>

<li>
<strong>Step 9b:</strong> 通过类YarnChild启动一个新jvm

<li>
<strong>Step 10:</strong> 从分布式缓存中获取运行task所需的资源：jar configuration etc.

<li>
<strong>Step 11:</strong> 运行这个task

</ol>

<p>
<strong>进度与状态报告:</strong>
</p>
<ol>
<li>
task向 <code>application master</code> 汇报进度与状态

<li>
<code>application master</code> 每三秒绘聚一次整个job的概况

<li>
client 每秒向 <code>application master</code> 拉取一次job的进度与状态

<ul>
<li>
可能通过属性 <code>mapreduce.client.progressmonitor.pollinterval</code> 修改这个时间值 

</ul>
</ol>
<p>
<img src="mapreduce_yarn_report.png" />
</p>

<p>
<strong>Job完成:</strong>
</p>
<ol>
<li>
client会向 <code>application master</code> 轮询job是否完成

<ul>
<li>
通过调用Job的方法waitForCompletion()

<li>
间隔时间通过属性 <code>mapreduce.client.completion.pollinterval</code> 指定

</ul>
<li>
一旦完成：

<ol>
<li>
<code>application master</code> 和 <code>containers</code> 执行cleanup操作

<li>
调用OutputCommiter的cleanup方法

<li>
job的信息被job history server归档

</ol>
</ol>

<h2 id="toc_1.2">处理失败</h2>

<h3 id="toc_1.2.1">经典MapReduce(MapReduce 1)的失败</h3>
<p>
<strong>task失败:</strong>
</p>
<ol>
<li>
RuntimeException

<ul>
<li>
退出前通知tasktracker

<li>
将这个task attempt标记为失败

<li>
tasktracker释放一个task slot,等待新的任务

</ul>
<li>
流式task非0退出码

<ul>
<li>
通过属性 <code>stream.non.zero.exit.is.failure</code> 设置

</ul>
<li>
jvm进程突然结束

<ul>
<li>
tasktracker发现task进程结束

<li>
将这次task attemp标记为失败

</ul>
<li>
task长时间挂起

<ul>
<li>
tasktracker在一定时间内收不到进度报告，标记为失败

<li>
通过属性 <code>mepred.task.timeout</code> 设置超时时间

<li>
0这关掉该特性，永不超时

</ul>
<li>
jobtracker 发现一个 task attempt 失败

<ul>
<li>
重新高度这个task

<li>
会尽量避免使用这个task上次失败所在的tasktracker

<li>
同一个task默认失败4次，就不会在重试

<li>
可以通过属性 <code>mapred.map.max.attempts</code> 和 <code>mapred.reduce.max.attempts</code> 设置

</ul>
<li>
task失败达到一定比例后，才会标记一个job的失败,job退出执行

<ul>
<li>
通过属性 <code>mapred.max.map.failures.percent</code> 和 <code>mapred.max.reduce.failures.percent</code> 设置

</ul>
</ol>

<p>
<strong>tasktracker失败:</strong>
</p>
<ol>
<li>
tasktracker失败，就不会向jobtracker发送心跳

<li>
jobtracker长时间收不到tasktracker的心跳，就会标记tasktracker失败

<ul>
<li>
通过属性设置这个时间 <code>mapred.tasktracker.expiry.interval</code> 默认为10分钟

</ul>
<li>
jobtracker会将该tasktracker从池中移出，不再参与task的分配

<li>
在那个tasktracker上所有未完成job的所有task都会重新执行，因为那个tasktracker的所在机器很可能不能访问了

<li>
tasktracker 黑名单

<ol>
<li>
同一个job的task失败数超过4个，就会标记该tasktracker失败，通过属性 <code>mapred.max.tracker.failures</code> 设置 

<li>
一个tasktracker失败超过4次，就会加入黑名单, 通过属性 <code>mapred.max.tracker.blacklists</code> 设置 

<li>
黑名单中的tasktracker不参与task的分配

<li>
黑名单有过期时间，为1天

</ol>
</ol>


<p>
<strong>jobtracker失败:</strong>
</p>
<ol>
<li>
这是很严重的错误，单点错误，没有有效的应对方案

<li>
一个失败的jobtracker重启后，会尝试恢复相关的job

<ol>
<li>
通过属性 <code>mapred.jobtracker.restart.recover</code> 开启这项功能，默认是关闭

<li>
但这项功能并不可靠，不见意使用

</ol>
</ol>

<h3 id="toc_1.2.2">YARN(MapReduce 2)中的失败</h3>
<p>
<strong>task失败:</strong>
</p>
<ol>
<li>
RuntimeException

<ul>
<li>
退出前通知 <code>application master</code> 

<li>
将这个task attempt标记为失败

</ul>
<li>
流式task非0退出码

<ul>
<li>
通过属性 <code>stream.non.zero.exit.is.failure</code> 设置

</ul>
<li>
jvm进程突然结束

<ul>
<li>
<code>application master</code> 发现task进程结束

<li>
将这次task attemp标记为失败

</ul>
<li>
task长时间挂起

<ul>
<li>
<code>application master</code> 在一定时间内收不到进度报告，标记为失败

<li>
通过属性 <code>mepred.task.timeout</code> 设置超时时间

<li>
0这关掉该特性，永不超时

</ul>
<li>
如何确定一个task的失败

<ul>
<li>
重试4次,还不成功

<li>
可以通过属性 <code>mapred.map.max.attempts</code> 和 <code>mapred.reduce.max.attempts</code> 设置

</ul>
<li>
task失败达到一定比例后，才会标记一个job的失败,job退出执行

<ul>
<li>
通过属性 <code>mapred.max.map.failures.percent</code> 和 <code>mapred.max.reduce.failures.percent</code> 设置

</ul>
</ol>

<p>
<strong>application master失败:</strong>
</p>
<ol>
<li>
实际上就是job的失败

<li>
job可以有重试一次，默认是一次

<ul>
<li>
可以通过属性 <code>yarn.resourcemanager.am.max-retries</code> 修改

</ul>
<li>
重试

<ol>
<li>
resource manager会分配一个新的container运行一个新的applicaiton master

<li>
application master会重新运行所有的task

<li>
但application master可以只运行那些还未成功的task

<li>
通过属性 <code>yarn.app.mapreduce.am.job.recovery.enable</code> 开启这个功能

<li>
client 会经历一个timeout后，从resource manager获取新 application master 的地址

</ol>
</ol>

<p>
<strong>node manager失败:</strong>
</p>
<ol>
<li>
node manager 失败

<li>
就不会向resource manager发送心跳

<li>
resouce manager长时间收不到心跳

<ul>
<li>
通过属性 <code>yarn.resourcemanager.ns.liveness-monitor.expiry-interval-ms</code> 设置

</ul>
<li>
resouce manager就会将结点从结点列表中去除

<li>
而在该结点上所有的task和application master都会根据前面的规则进行recovery

<li>
node manager黑名单

<ul>
<li>
超过三个task失败

<li>
通过属性 <code>mapreduce.job.maxtaskfailures.per.tracker</code> 设置

</ul>
</ol>
   
<p>
<strong>resource manager失败:</strong>
</p>
<ol>
<li>
resouce manager被设计成可以持久化保持状态

<li>
resouce manager失败后

<li>
resouce manager会重启并恢复状态

<li>
状态信息由node managers和正在运行的job组成

</ol>

<h2 id="toc_1.3">Job的调度</h2>

<h2 id="toc_1.4">Shuffle和排序</h2>

<h2 id="toc_1.5">Task的运行</h2>

			</div>

			<div id="bottom">
				&copy; 2012 王兴朝
			</div>
		</div>
	<div>
</body>
</html>
