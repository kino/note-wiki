<!DOCTYPE html>
<html>
<head>

<title>Hadoop File System</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<script type="text/javascript" src="../../js/jquery-1.6.4.min.js"></script>

<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shCore.css">
<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shThemeRDark.css">
<script type="text/javascript" src="../../js/sh/scripts/shCore.js"></script>
<script type="text/javascript" src="../../js/sh/scripts/shAutoloader.js"></script>

<script type="text/javascript" src="../../js/main.js"></script>
<script type="text/javascript" src="../../js/ASCIIMathML.js"></script>

<link rel="Stylesheet" type="text/css" href="../../style.css">
<link rel="Stylesheet" type="text/css" href="../../css/main.css">

</head>
<body>
	<div class="hidden">
		<input id="root_path" type="text" value="../../">
	</div>
	<div id="body-wrapper">
		<div id="container">
			<div id="top">
				<div id="page-title">
					<a href="../../index.html">烂笔头</a>
				</div>
				<ul id="top-nav">
				</ul>
			</div>
			<div id="middle">
				
<div class="toc">
<ul>
<li><a href="#toc_1">Hadoop File System</a>
<ul>
<li><a href="#toc_1.1">HDFS的设计 </a>
<li><a href="#toc_1.2">HDFS</a>
<ul>
<li><a href="#toc_1.2.1">数据块 </a>
<li><a href="#toc_1.2.2">namenode &amp; datanode</a>
<li><a href="#toc_1.2.3">命令行接口 </a>
<li><a href="#toc_1.2.4">基本文件系统操作</a>
<li><a href="#toc_1.2.5">Hadoop文件系统</a>
<li><a href="#toc_1.2.6">接口</a>
<li><a href="#toc_1.2.7">JAVA接口</a>
</ul>
<li><a href="#toc_1.3">数据流 </a>
<ul>
<li><a href="#toc_1.3.1">文件读取剖析</a>
<li><a href="#toc_1.3.2">如何衡量节点的距离 </a>
<li><a href="#toc_1.3.3">文件写入分析</a>
</ul>
</ul>
</ul>
</div>
<h1 id="toc_1">Hadoop File System</h1>
<ul>
<li>
当数据集大小超过一台物理机器，需要对它分区存储到不同的机器上。

<li>
跨机器管理存储的文件系统称之为分布式文件系统，Distributed File System

<li>
HDFS: Hadoop distributed file system.

</ul>

<h2 id="toc_1.1">HDFS的设计 </h2>
<ul>
<li>
<strong>超大文件:</strong> MB GB TB PB 

<li>
<strong>流式数据访问:</strong>

<ul>
<li>
一次写入，多次读入

<li>
每次数据分析涉及数据集中的大部分或全部

</ul>
<li>
<strong>商业硬件:</strong> 并不需要运行在昂贵的可靠的商业硬件上

<li>
<strong>商业硬件:</strong> 并不需要运行在昂贵的可靠的商业硬件上

<li>
<strong>低时间延迟的访问:</strong>

<ul>
<li>
不适合低时间延迟的访问，比如几十毫秒

<li>
为高吞吐量做的优化， 但可能会高时间延迟为代价

</ul>
<li>
<strong>大量小文件:</strong>

<ul>
<li>
元数据存储在Namenode上

<li>
文件总数的大小依赖于Namenode的内存大小 

</ul>
<li>
<strong>不支持多用户写和多用户同时修改:</strong>

</ul>
 
<h2 id="toc_1.2">HDFS</h2>
<h3 id="toc_1.2.1">数据块 </h3>
<ul>
<li>
<strong>磁盘块:</strong> 磁盘进行读写的最小单位, 一般为512字节

<li>
文件系统块是磁盘块的整数倍，一般为几千字节

<li>
HDFS的块默认为64m

<ul>
<li>
小于一个块大小的文件不会占满一个块

<li>
块设的大是为了最小化寻址开销

<li>
块过大也不行，mapreduce一次处理一个块

<li>
块的大小要根据实际情况来调整，比如寻址占传输时间的1/100

</ul>
<li>
使用块的好处

<ul>
<li>
一个文件的大小可以大于任意一个磁盘的大小

<li>
简化了存储子系统，文件的元数据不和块数据存储在一起

<li>
适合备份和容错，任何一个块都有复本。

</ul>
</ul>
<h3 id="toc_1.2.2">namenode &amp; datanode</h3>
<ul>
<li>
管理者 工作者模式

<li>
namenode:

<ul>
<li>
管理者

<li>
管理文件系统的命名空间

<li>
维护文件系统树及树内所的目录与文件

<li>
信息以两个文件永久保存：命名空间镜像文件与编辑日志文件

<li>
记录文件中每个块所在数据结点的信息，但不永久保存，系统启动时重建

</ul>
<li>
datanode:

<ul>
<li>
工作者

<li>
存储校验数据块

<li>
定期向namenode发送数据块列表

</ul>
<li>
失去namenode等于失去文件系统，所namenode容错非常重要：

<ul>
<li>
备份namenode上的元数据，多份同进写

<li>
使用辅助namenode, 定期合并编辑日志生成空间镜像

</ul>
</ul>
<h3 id="toc_1.2.3">命令行接口 </h3>
<h3 id="toc_1.2.4">基本文件系统操作</h3>
<pre  class="brush:bash">
hadoop fs -help
</pre>
  
<h3 id="toc_1.2.5">Hadoop文件系统</h3>
<ul>
<li>
是一个气象的文件系统

<li>
<strong>HDFS只是它的一个实现 </strong>

<li>
抽象类定义了一个文件系统接口：<code>org.apache.hadoop.fs.FileSystem</code>

<li>
还有很多其他实现：Local HDFS HFTP HSFTP HAR hfs FTP S3 

</ul>

<h3 id="toc_1.2.6">接口</h3>
<ul>
<li>
java

<li>
C

<li>
Thrift

<li>
WebDev

<li>
FUSE

<li>


<li>
HDFS两种特定的

<ul>
<li>
HTTP: namenode 50070; datanode 50075

<li>
FTP

</ul>
</ul>
<h3 id="toc_1.2.7">JAVA接口</h3>
<ul>
<li>
<strong>Configuration FileSystem FSDataInpuStream FSDataOutputStream Path FileStatus PathFileter</strong>

<li>
<strong>Configuration</strong>

<ol>
<li>
文件系统的配置

</ol>
<li>
<strong>FileSystem</strong>

<ol>
<li>
代表文件系统

<li>
FileSystem.get(uri, config) :创建

<li>
FSDataInputStream open(path) :获取指定文件的输入流

<li>
FSDataOutputStream create(path) :创建一个文件并获得它的输出流

<li>
FSDataOutputStream append(path) :获取指定文件的输出流，并在其后添加数据

<li>
boolean mkdirs(path) :创建必要但还没有的父目录

<li>
FileStatus getFileStatus(path) : 获取指定文件的文件状态

<li>
FileStatus[] globFileStatus(path) : 获取与文件相匹配的所有文件的文件状态

<li>
FileStatus[] globFileStatus(path， pathFilter) : 获取与文件相匹配的所有文件的文件状态

<li>
FileStatus[] listFileStatus(path) : 用来列目录

<li>
FileStatus[] listFileStatus(path， pathFilter) : 用来列目录

<li>
boolean delete(path, boolean recursive) : 删除文件或目录， 是否递归删除

</ol>
<li>
<strong>FSDataInputStream</strong>

<ol>
<li>
支持随机访问

<li>
seek(long):设置postion

<li>
long getPos():获取postion

<li>
int read(long position, byte[] buffer, int offset, int length)

<li>
void readFully(long position, byte[] buffer, int offset, int length)

<li>
void readFully(byte[] buffer, int offset, int length)

</ol>
<li>
<strong>FSDataOutputStream</strong>

<ol>
<li>
用于写数据 

<li>
支持随机访问

<li>
long getPos():设置postion

<li>
但不允许定位

<li>
只支持对一个打开的文件从头顺序写入， 或从末尾处添加

</ol>
<li>
<strong>FileStatus</strong>

<ol>
<li>
用于查询一个文件状态

</ol>
<li>
<strong>Path</strong>

<ol>
<li>
代表一个文件路径

</ol>
<li>
<strong>PathFileter</strong>

<ol>
<li>
当listStatus时，过滤文件

</ol>
<li>
例子：

<ol>
<li>
读

<li>
写

<li>
目录

<li>
列文件

<li>
删除

</ol>
</ul>
   
<h2 id="toc_1.3">数据流 </h2>
<h3 id="toc_1.3.1">文件读取剖析</h3>
<p>
<img src="reading-data-from-hdfs.png" />
</p>
<ol>
<li>
fileSystem.open打开要读取的文件 

<ul>
<li>
这个文件就是HDFS分布式文件系统中的一个实例

</ul>
<li>
DistributedFileSystem通过RPC调用NameNode确定文件 *起始块* 所在的位置

<ul>
<li>
NameNode返回所有包含该块的DataNode地址

<li>
并按网络距离排序

<li>
比如客户端所在就是一个DataNode, 而该块在此DataNode上刚好存有复本，就会发起本地读取

<li>
返回一个FSDataInputStream对象，供客户端使用. 进而转而封装为HdfsDataInputStream,管理着Namenode和Datanode之间的io

</ul>
<li>
对输入流(FSDataInputStream)调用read()方法

<li>
HdfsDataInputStream会从最近的Datanode读入

<ul>
<li>
不停的read()直到块的末尾

</ul>
<li>
HdfsDataInpuStream会寻找  <strong>下一个块</strong>  的 <strong>最优Datanode</strong> 继续读取

<ul>
<li>
对于 <strong>下一块 </strong> 也需要向Namenode查询所需的Datanode

</ul>
<li>
读取完毕调用FSDataInputStream的close()方法进行关闭

</ol>
 
<ul>
<li>
<strong>HdfsDataInputStream与Datanode通信出错时：</strong>

<ol>
<li>
尝试比这个Datanode次邻近的Datanode读取

<li>
它会记住这个出错的Datanode,后续的块也不会从这里读取

<li>
它也会校验读取的数据是否完整,如果发现损坏的块

<li>
如果不完整，再尝试从其他Datanode读取数据之前，通知Namenode

</ol>
<li>
<strong>设计优劣:</strong>

<ol>
<li>
Namenode告知client最佳的Datanode

<li>
client直接从Datenode取数据

<li>
因为Datanode分散在集群中

<li>
所以很容易扩展到大量并发客户端

<li>
Namenode仅提供块位置请求，而不提供数据请求，很高效

<li>
随着客户端的增加， Namenode还是会成为瓶颈

</ol>
</ul>

<h3 id="toc_1.3.2">如何衡量节点的距离 </h3>
<ul>
<li>
海量数据处理中，主要的限制因素是节点间的传输速率 -- 带宽

<li>
将带宽作为衡量距离的标准

<li>
带宽是很难衡量比较的

<li>
Hadoop采用了一个简单的方法，以下带宽以次递减

<ol>
<li>
同一节点中的不同进程

<li>
同一机架上的不同节点

<li>
同一数据中心不同机架上的节点

<li>
不同数据中心里的节点

</ol>
<li>
这些信息需要我们辅助定义

</ul>

<h3 id="toc_1.3.3">文件写入分析</h3>
<p>
<img src="writing-data-from-hdfs.png" />
</p>
<ol>
<li>
调用DistributedFileSystem的create()来创建文件

<li>
DistributedFileSystem对namenode发起一个RPC, 在文件系统命名空间中创建一个文件，此时还没有数据块

<ul>
<li>
namenode执行各种检查确保要创建的文件还不存在

<li>
namenode检查客户端的权限

<li>
检查通过为新文件添加一条记录， 否则抛出异常

<li>
返回一个FSDataOutputStream,  里面封装了HdfsOutputStream, 负责datanode与namenode之间的通信

</ul>
<li>
调用write()写入数据

<ul>
<li>
HdfsOutputStream将数据分成一个个数据包，并写入内部队列data queue

<li>
DataStreamer 处理数据队列

<li>
它根据datanode列表要求namenode分配相应的块来写入数据备份

<li>
这组datanode组成一个管线，其中的数目就是我们所高的备份数replication

</ul>
<li>
DataStreamer将数据包流式传入管线中的第一个节点的datanode

<ul>
<li>
该datanode存储数据并同时把数据发往管线中的下一个datanode

<li>
以此类推，datanode在存储数据的同时发往管线中的下一个datanode(如果存在的话，也就是直到最后一个）

</ul>
<li>
HdfsOutputStream等待datanode的确认返回 ack queue

<ul>
<li>
HdfsOutStream维护了一个内部队列，等待daqanode的确认返回, 称为确认队列ack queue

</ul>
<li>
数据写入完毕,调用close()方法

<ul>
<li>
触发将剩余的数据包写入管线中

<li>
向namenode发送确认完成信号

</ul>
<li>
向namenode发送确认完成信号（在close方法内部）

<ul>
<li>
namenode已知文件由哪些数据块组成

<li>
因DataStreamer曾要求namenode分配数据块

<li>
等待数据块进行最小量的复制

<li>
完成返回

</ul>
</ol>

			</div>

			<div id="bottom">
				&copy; 2012 王兴朝
			</div>
		</div>
	<div>
</body>
</html>
