<!DOCTYPE html>
<html>
<head>

<title>Administering Hadoop </title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<script type="text/javascript" src="../../js/jquery-1.6.4.min.js"></script>

<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shCore.css">
<link rel="Stylesheet" type="text/css" href="../../js/sh/styles/shThemeRDark.css">
<script type="text/javascript" src="../../js/sh/scripts/shCore.js"></script>
<script type="text/javascript" src="../../js/sh/scripts/shAutoloader.js"></script>

<script type="text/javascript" src="../../js/main.js"></script>
<script type="text/javascript" src="../../js/ASCIIMathML.js"></script>

<link rel="Stylesheet" type="text/css" href="../../style.css">
<link rel="Stylesheet" type="text/css" href="../../css/main.css">

</head>
<body>
	<div class="hidden">
		<input id="root_path" type="text" value="../../">
	</div>
	<div id="body-wrapper">
		<div id="container">
			<div id="top">
				<div id="page-title">
					<a href="../../index.html">烂笔头</a>
				</div>
				<ul id="top-nav">
				</ul>
			</div>
			<div id="middle">
				
<h1 id="toc_1"> Administering Hadoop</h1>

<div class="toc">
<ul>
<li><a href="#toc_1"> Administering Hadoop</a>
<ul>
<li><a href="#toc_1.1">1 HDFS</a>
<ul>
<li><a href="#toc_1.1.1">1.1 持久化数据结构 </a>
<ul>
<li><a href="#toc_1.1.1.1">1.1.1 Namenode的目录结构 </a>
<li><a href="#toc_1.1.1.2">1.1.2 文件系统映象与编辑日志 </a>
<li><a href="#toc_1.1.1.3">1.1.3 Secondary Namenode的目录结构 </a>
<li><a href="#toc_1.1.1.4">1.1.4 Datanode的目录结构 </a>
</ul>
<li><a href="#toc_1.1.2">1.2 安全模式</a>
<li><a href="#toc_1.1.3">1.3 进入与离开安全模式</a>
<li><a href="#toc_1.1.4">1.4 审核日志</a>
<li><a href="#toc_1.1.5">1.5 工具集 </a>
<ul>
<li><a href="#toc_1.1.5.1">1.5.1 dfsadmin</a>
<li><a href="#toc_1.1.5.2">1.5.2 fsck</a>
<li><a href="#toc_1.1.5.3">1.5.3 datanode block scanner</a>
<li><a href="#toc_1.1.5.4">1.5.4 balancer</a>
</ul>
</ul>
<li><a href="#toc_1.2">2 监控</a>
<ul>
<li><a href="#toc_1.2.1">2.1 日志</a>
<ul>
<li><a href="#toc_1.2.1.1">2.1.1 设置日志级别</a>
<li><a href="#toc_1.2.1.2">2.1.2 获取堆栈</a>
</ul>
<li><a href="#toc_1.2.2">2.2 度量</a>
<ul>
<li><a href="#toc_1.2.2.1">2.2.1 FileContext</a>
<li><a href="#toc_1.2.2.2">2.2.2 GangliaContext</a>
<li><a href="#toc_1.2.2.3">2.2.3 NullContextWithUpdateThread</a>
<li><a href="#toc_1.2.2.4">2.2.4 CompositeContext</a>
</ul>
<li><a href="#toc_1.2.3">2.3 JMX</a>
</ul>
<li><a href="#toc_1.3">3 维护</a>
<ul>
<li><a href="#toc_1.3.1">3.1 日常维护</a>
<ul>
<li><a href="#toc_1.3.1.1">3.1.1 元数据备份 </a>
<li><a href="#toc_1.3.1.2">3.1.2 数据备份</a>
<li><a href="#toc_1.3.1.3">3.1.3 文件系统备份</a>
<li><a href="#toc_1.3.1.4">3.1.4 文件系统Balancer</a>
</ul>
<li><a href="#toc_1.3.2">3.2 添加或移除结点 </a>
<ul>
<li><a href="#toc_1.3.2.1">3.2.1 添加新结点 </a>
<li><a href="#toc_1.3.2.2">3.2.2 移除老结点 </a>
</ul>
<li><a href="#toc_1.3.3">3.3 升级</a>
<ul>
<li><a href="#toc_1.3.3.1">3.3.1 HDFS 数据与元数据升级</a>
</ul>
</ul>
</ul>
</ul>
</div>

<h2 id="toc_1.1">1 HDFS</h2>

<h3 id="toc_1.1.1">1.1 持久化数据结构 </h3>
<p>
Namenode, Secondary Namenode, Datanode在磁盘上数据是如何存储组织的。
</p>

<h4 id="toc_1.1.1.1">1.1.1 Namenode的目录结构 </h4>
<pre  class="brush:bash">
    ${dfs.name.dir}/
    └── current/
        ├── VERSION
        ├── edits
        ├── fsimage
        └── fstime
</pre>
<ol>
<li>
dfs.name.dir 可以指定几个文件夹列表

<li>
每个文件夹中存放相同的数据

<li>
推荐其中一个使用NFS文件夹

<li>
文件VERSION：
<pre  class="brush:bash">
    #Tue Mar 10 19:21:36 GMT 2009
    namespaceID=134368441 #文件系统的唯一id号
                          #文件系统第一次格式化时创建
                          #用于检测新添加的datanode,因为它们不知道这个id号
    cTime=0 # namenode存储创建的时间
            # 对于新格式化的设备总是0
            # 升级时会更新这个时间
    storageType=NAME_NODE # 表名该文件夹存储什么样的数据
                          # 这个文件夹说明存放namenode的数据
    layoutVersion=-18 # 文件系统存储数据所使用结构的版本
                      # 是一个负数
                      # 升级会变成一个更小的负数，下一个版本-19
</pre>

</ol>

<h4 id="toc_1.1.1.2">1.1.2 文件系统映象与编辑日志 </h4>
<p>
<strong>编辑日志edit log:</strong>
</p>
<ol>
<li>
当对HDFS进行一个写操作时

<li>
就会在edit log中产生一条记录

<li>
namenode会在内存中保留一份整个HDFS的元数据

<ul>
<li>
它会在edit log更改后更改

<li>
它服务于对HDFS的读操作

</ul>
<li>
edit log的flush与sync

<ul>
<li>
它会在向客户端返回success code之前进行

<li>
namenode需要写多个目录

<li>
要保证每一个目录都写到了，才返回

</ul>
</ol>

<p>
<strong>fsimage:</strong>
</p>
<ol>
<li>
HDFS元数据checkpoint的持久化数据

<li>
并不是每个写操作都会触发更新，否则的话这个文件会增长过快

<li>
当namenode失败时

<ol>
<li>
会通过该文件恢复内存中的元数据

<li>
replay edit log中的操作

</ol>
<li>
namenode启动时就是进行的上述操作

</ol>
 
<p>
<strong>fsimage中的内容:</strong>
</p>
<ol>
<li>
HDFS中所有文件和目录的inodes

<li>
一个inode代表一个文件或目录的元数据

<li>
对于文件

<ul>
<li>
replication level

<li>
modification and access times

<li>
access permissions

<li>
block size

<li>
由哪些blocks组成

</ul>
<li>
对于目录

<ul>
<li>
modification time

<li>
permissions

<li>
quota metadata is stored.

</ul>
</ol>

<p>
edit log并没有大小限制，而namenode运行时，并不会有影响，
但当namenode重启时，会花很长的时间replay这个文件里的操作.
解决方案就是使用secondary namenode.
</p>

<p>
<strong>secondary namenode:</strong>
</p>
<ol>
<li>
用于根据主结点中的内存元数据生成checkpoint

<li>
进程的处理过程:

<ol>
<li>
The secondary asks the primary to roll its edits file, so new edits go to a new file.

<li>
The secondary retrieves fsimage and edits from the primary (using HTTP GET).

<li>
The secondary loads fsimage into memory, applies each operation from edits, then
    creates a new consolidated fsimage file.

<li>
The secondary sends the new fsimage back to the primary (using HTTP POST).

<li>
The primary replaces the old fsimage with the new one from the secondary and the
    old edits file with the new one it started in step 1. It also updates the fstime file to
    record the time that the checkpoint was taken.

</ol>
<li>
最后primary就会拥有一个最新的fsimage文件和一个小的edit log 文件

<li>
管理员可以手动触发这个操作: <code>hadoop dfsadmin -saveNamespace</code>

<li>
这个过程的自动触发有两种情况

<ul>
<li>
每小时触发一次，由属性 <code>fs.checkpoint.period</code> 指定

<li>
当edit log到达64MB时，由属性 <code>fs.checkpoint.size</code> 指定

</ul>
<li>
由上面可看出secondary namenode需要有和namenode相近的内存

</ol>
<p>
<img src="namenode-checkpointing.png" />
</p>

<h4 id="toc_1.1.1.3">1.1.3 Secondary Namenode的目录结构 </h4>
<pre  class="brush:bash">
    ${fs.checkpoint.dir}/
    ├── current/
    │   ├── VERSION
    │   ├── edits
    │   ├── fsimage
    │   └── fstime
    └── previous.checkpoint/
         ├── VERSION
         ├── edits
         ├── fsimage
         └── fstime
</pre>
<ol>
<li>
checkpointing进程完毕后，secondary namenode也会拥有一个检查点,放在文件夹previous.checkpoint里

<li>
这份数据可以作为namenode元数据的备份

<li>
secondary namenode的current，previous checkpoint和主namenode的元数据文件夹的结构是一样的

<li>
namenode失败时

<ol>
<li>
可以通过-importCheckpoint选项启动secondary namenode, 其将作为主namenode

<li>
它会从fs.checkpoint.dir文件夹里获取最新元数据放入dfs.name.dir里

</ol>
</ol>

<h4 id="toc_1.1.1.4">1.1.4 Datanode的目录结构 </h4>
<pre  class="brush:bash">
    ${dfs.data.dir}/
    └── current/
         ├── VERSION
         ├── blk_&lt;id_1&gt;
         ├── blk_&lt;id_1&gt;.meta
         ├── blk_&lt;id_2&gt;
         ├── blk_&lt;id_2&gt;.meta
         ├── ...
         ├── blk_&lt;id_64&gt;
         ├── blk_&lt;id_64&gt;.meta
         ├── subdir0/
         ├── subdir1/
         ├── ...
         └── subdir63/
</pre>
<ol>
<li>
datanode的目录不需要预先格式化，它会在启动时自动创建

<li>
同namenode一样，这里也会有一个VERSION文件

<ul>
<li>
namespceID, cTime 和 layoutVersion同namenode里的一样

<li>
namespceID是从namenode里接收的, 当datanode第一次连接时

<li>
storgeID是全局内是唯一的，namenode用它来唯一确定一个datanode

<li>
storageType用于表明该目录是做什么用的，这里是用于存储datanode数据的

</ul>
<li>
两种以blk_为前缀的文件

<ul>
<li>
一种就是HDFS块, 存储原始数据

<li>
第二种是HDFS块的元数据，以.meta为后缀， 存放了版本与类型信息，接着是一系列的校验值

</ul>
<li>
当HDFS块的数量到达一定数量后，会创建一个子目录，用于存放新的块和它们的元数据

<ul>
<li>
通过属性 <code>dfs.datanode.numblocks</code> 设置这个数据

<li>
保证了每个文件夹拥有可维护数量的文件

</ul>
<li>
若dfs.data.dir设置了多个目录，分属于不同的磁盘

<ul>
<li>
HDFS会轮循使用这些目录

<li>
不同的目录下不会有重复的块，只有不同的datanode间才有不同的块

</ul>
</ol>

<h3 id="toc_1.1.2">1.2 安全模式</h3>
<p>
<strong>Namenode的启动:</strong>
</p>
<ol>
<li>
加载fsimage进内存

<li>
接收edit log中的所有操作进内存

<li>
内存中构建出一份新的fsimage

<li>
创建一份新的空的edit log

<li>
开始监听RPC和HTTP请求

</ol>
 
<p>
<strong>安全模式:</strong>
</p>
<ol>
<li>
上面最后一步前是运行于安全模式的

<li>
可运行读元数据的操作，但也不保证完成

<li>
读文件的操作，只有当文件的块全部就绪后才可以

<li>
修改操作会全部失败

</ol>
 
<p>
<strong>namenode不维护hdfs block的位置信息:</strong>
</p>
<ol>
<li>
namenode不会持久化hdfs block的位置信息

<li>
namenode在内存中会有一份这样的信息

<li>
在安全模式下，datanode会告诉namenode它所包含的datanode列表

<li>
在安全模式下，不会对datanode 进行任何复本操作和删除操作

<li>
安全模式退出的条件：

<ol>
<li>
达到最小复本条件，再等30秒

<li>
最小复本条件默认是99%的块达到了复本要求

</ol>
<li>
新格式化的hdfs集群， namenode并不会进行安全模式

</ol>
<table>
<tr>
<td>
Property name
</td>
<td>
Type
</td>
<td>
Default value
</td>
<td>
Description
</td>
</tr>
<tr>
<td>
dfs.replication.min
</td>
<td>
int
</td>
<td>
1
</td>
<td>
The minimum number of replicas that have to be written for a write to be successful.
</td>
</tr>
<tr>
<td>
dfs.safemode.threshold.pct
</td>
<td>
float
</td>
<td>
0.999
</td>
<td>
The proportion of blocks in the system that must meet the minimum replication level defined by dfs.replication.min before the namenode will exit safe mode. Setting this value to 0 or less forces the namenode not to start in safe mode. Setting this value to more than 1 means the namenode never exits safe mode.
</td>
</tr>
<tr>
<td>
dfs.safemode.extension
</td>
<td>
int
</td>
<td>
30,000
</td>
<td>
The time, in milliseconds, to extend safe mode after the minimum replication condition defined by dfs.safemode.threshold.pct has been satisfied.  For small clusters (tens of nodes), it can be set to 0.
</td>
</tr>
</table>

<h3 id="toc_1.1.3">1.3 进入与离开安全模式</h3>
<ol>
<li>
查看namenode是否在安全模式
<pre  class="brush:bash">
     % hadoop dfsadmin -safemode get
</pre>

<li>
等待namenode退出安全模式
<pre  class="brush:bash">
     hadoop dfsadmin -safemode wait
     # command to read or write a file
</pre>

<li>
使namenode进入安全模式
<pre  class="brush:bash">
     % hadoop dfsadmin -safemode enter
</pre>

<li>
使namenode离开安全模式
<pre  class="brush:bash">
     % hadoop dfsadmin -safemode leave
</pre>

</ol>

<h3 id="toc_1.1.4">1.4 审核日志</h3>
<p>
hadoop可以对所有的访问记录日志。
默认没有打开，可以在log4j的配置文件里打开
</p>

<h3 id="toc_1.1.5">1.5 工具集 </h3>
<h4 id="toc_1.1.5.1">1.5.1 dfsadmin</h4>
<table>
<tr>
<th>
Command
</th>
<th>
Description
</th>
</tr>
<tr>
<td>
-help
</td>
<td>
Shows help for a given command, or all commands if no command is specified.
</td>
</tr>
<tr>
<td>
-report
</td>
<td>
Shows filesystem statistics (similar to those shown in the web UI) and information on connected datanodes.
</td>
</tr>
<tr>
<td>
-metasave
</td>
<td>
Dumps information to a file in Hadoop’s log directory about blocks that are being replicated or deleted, as well as a list of connected datanodes.
</td>
</tr>
<tr>
<td>
-safemode
</td>
<td>
Changes or queries the state of safe mode. See “Safe Mode” on page 344.
</td>
</tr>
<tr>
<td>
-saveNamespace
</td>
<td>
Saves the current in-memory filesystem image to a new fsimage file and resets the edits file. This operation may be performed only in safe mode.
</td>
</tr>
<tr>
<td>
-refreshNodes
</td>
<td>
Updates the set of datanodes that are permitted to connect to the namenode. See “Commissioning and Decommissioning Nodes” on page 359.
</td>
</tr>
<tr>
<td>
-upgradeProgress
</td>
<td>
Gets information on the progress of an HDFS upgrade or forces an upgrade to proceed. See “Upgrades” on page 362.
</td>
</tr>
<tr>
<td>
-finalizeUpgrade
</td>
<td>
Removes the previous version of the namenode and datanode storage directories. Used after an upgrade has been applied and the cluster is running successfully on the new version. See “Upgrades” on page 362.
</td>
</tr>
<tr>
<td>
-setQuota
</td>
<td>
Sets directory quotas. Directory quotas set a limit on the number of names (files or directories) in the directory tree. Directory quotas are useful for preventing users from creating large numbers of small files, a measure that helps preserve the namenode’s memory (recall that accounting information for every file, directory, and block in the filesystem is stored in memory).
</td>
</tr>
<tr>
<td>
-clrQuota
</td>
<td>
Clears specified directory quotas.
</td>
</tr>
<tr>
<td>
-setSpaceQuota
</td>
<td>
Sets space quotas on directories. Space quotas set a limit on the size of files that may be stored in a directory tree. They are useful for giving users a limited amount of storage.
</td>
</tr>
<tr>
<td>
-clrSpaceQuota
</td>
<td>
Clears specified space quotas.
</td>
</tr>
<tr>
<td>
-refreshServiceAcl
</td>
<td>
Refreshes the namenode’s service-level authorization policy file.
</td>
</tr>
</table>

<h4 id="toc_1.1.5.2">1.5.2 fsck</h4>
<p>
用于检查HDFS和HDFS中文件的健康状况。
</p>
<pre  class="brush:bash">
    % hadoop fsck /
    ......................Status: HEALTHY
    Total size:
    511799225 B
    Total dirs: 10
    Total files: 22
    Total blocks (validated): 22 (avg. block size 23263601 B)
    Minimally replicated blocks: 22 (100.0 %)
    Over-replicated blocks: 0 (0.0 %)
    Under-replicated blocks: 0 (0.0 %)
    Mis-replicated blocks: 0 (0.0 %)
    Default replication factor: 3
    Average block replication: 3.0
    Corrupt blocks: 0
    Missing replicas: 0 (0.0 %)
    Number of data-nodes: 4
    Number of racks: 1
</pre>
  
<ol>
<li>
fsck仅仅从namenode获取数据

<li>
不会和任何datanode通信

<li>
也不会获取任何文件数据

<li>
重要属性说明：

<ul>
<li>
<strong>Over-replicated blocks:</strong> 复本数量超过指定的数量，通常不是什么问题，namenode会删除不需要的

<li>
<strong>Under-replicated blocks:</strong> 复本数量不足指定的数量，namenode会自动补足

<li>
<strong>Misreplicated blocks:</strong> 不符合复本策略，比如多机架环境，复本都在同一机架，namenode会自动调整 

<li>
<strong>Corrupt blocks:</strong> 损坏复本的块，如果复本中至少有一个正常的，就不会报告这项，而是namenode就会修复 

<li>
<strong>Missing replicas:</strong> 丢失所有复本 

</ul>
<li>
Corrupt和Missing是着重注意的，意味着数据已丢失，下面两个选项可以对这两种文件进行附加操作

<ul>
<li>
<strong>-move</strong> 移动到hdfs中的/lost+found文件夹中 

<li>
<strong>-delete</strong> 直接删除

</ul>
<li>
获取一个文件的块信息
<pre  class="brush:bash">
      % hadoop fsck /user/tom/part-00007 -files -blocks -racks
      /user/tom/part-00007 25582428 bytes, 1 block(s): OK
      0. blk_-3724870485760122836_1035 len=25582428 repl=3 [/default-rack/10.251.43.2:50010,
      /default-rack/10.251.27.178:50010, /default-rack/10.251.123.163:50010]
</pre>

<ul>
<li>
<strong>-files</strong>  显示 文件名 大小 块数量 健康状态

<li>
<strong>-blocks</strong> 显示每个块的信息

<li>
<strong>-racks</strong> 显示每个块的机架信息和datanode

</ul>
</ol>

<h4 id="toc_1.1.5.3">1.5.3 datanode block scanner</h4>
<ol>
<li>
用于定期检查验证一个datanode上所有的块

<li>
可以查出并修复损坏的块

<li>
它维护了一个需要检查块的列表

<li>
块默认每三周检查一次，可以通过属性dfs.datanode.scan.period.hours设置

<li>
通过<a href="http://datanode:50075/blockScannerReport">http://datanode:50075/blockScannerReport</a> 查看报表

<li>
通过<a href="http://datanode:50075/blockScannerReport?listblocks">http://datanode:50075/blockScannerReport?listblocks</a> 查看每一块的信息

</ol>
    
<h4 id="toc_1.1.5.4">1.5.4 balancer</h4>
<ol>
<li>
随着使用，集群中的datanode将变的不平衡，有些过度使用，有些使用很少

<li>
balancer 是一个守护进程，可以调整这种不平衡，将一些块从过度使用的datanode移到不常使用的datanode

<li>
需要遵守复本策略

<li>
拥有一个根据磁盘带宽，节流的机制

<li>
工作到直到集群平衡

<ul>
<li>
datanode的使用比例和整个集群的使用比例在一个误差范围内，默认是10％

<li>
手工运行时，可以通过参数-threshold指定

</ul>
<li>
手工运行
<pre  class="brush:bash">
      % start-balancer.sh
</pre>

<li>
一个时刻只能有一个实例运行

<li>
最终会通过日志的方式产生一个报告

<li>
默认限制datanode拷贝数据时的带宽大约为10M/s, 可能通过在hdfs-site.xml中的属性dfs.balance.bandwidthPerSec设置，

</ol>

<h2 id="toc_1.2">2 监控</h2>
<h3 id="toc_1.2.1">2.1 日志</h3>
<p>
每个守护里程都会产生日志。
</p>

<h4 id="toc_1.2.1.1">2.1.1 设置日志级别</h4>
<ol>
<li>
可以动态调整日志级别

<li>
通过网页调整

<ul>
<li>
比如 <a href="http://jobtracker-host:50030/logLevel">http://jobtracker-host:50030/logLevel</a>

</ul>
<li>
通过命令调整
<pre  class="brush:bash">
       % hadoop daemonlog -setlevel jobtracker-host:50030  org.apache.hadoop.mapred.JobTracker DEBUG
</pre>

</ol>

<h4 id="toc_1.2.1.2">2.1.2 获取堆栈</h4>
<ol>
<li>
任何一个守护进程都可以通过网页获取一个线程的堆栈

<li>
比如 <a href="http://jobtracker-host:50030/stacks.">http://jobtracker-host:50030/stacks.</a>

</ol>

<h3 id="toc_1.2.2">2.2 度量</h3>
<ol>
<li>
HDFS和MapReduce的守护进程都会收集度量信息

<li>
比如，datanode收集：写入字节数， 复本块数，客户端请求数

<li>
这些度量会分四大类：

<ul>
<li>
dfs

<li>
mapred

<li>
rpc

<li>
jvm

</ul>
<li>
配置文件conf/hadoop-metrics.properties来控制开启如些度量信息，默认是不开启的
<pre  class="brush:bash">
      dfs.class=org.apache.hadoop.metrics.spi.NullContext
      mapred.class=org.apache.hadoop.metrics.spi.NullContext
      jvm.class=org.apache.hadoop.metrics.spi.NullContext
      rpc.class=org.apache.hadoop.metrics.spi.NullContext
</pre>

</ol>

<h4 id="toc_1.2.2.1">2.2.1 FileContext</h4>
<ol>
<li>
将度量信息写入本地文件

<li>
支持两个配置属性

<ol>
<li>
jvm.fileName

<li>
jvm.period 不设为默认为5s
<pre  class="brush:bash">
      jvm.class=org.apache.hadoop.metrics.file.FileContext
      jvm.fileName=/tmp/jvm_metrics.log
</pre>

</ol>
</ol>

<h4 id="toc_1.2.2.2">2.2.2 GangliaContext</h4>
<ol>
<li>
一个开源的针对大规模集群的分布式监控系统

<li>
支持一个配置属性：servers, 以空格和逗号分隔的被监控服务器列表

</ol>
 
<h4 id="toc_1.2.2.3">2.2.3 NullContextWithUpdateThread</h4>
<ol>
<li>
不会往外吐数据，但会进行统计的，统计的信息在内存中

<li>
可以通过JMX暴露出去

</ol>
 
<h4 id="toc_1.2.2.4">2.2.4 CompositeContext</h4>
<ul>
<li>
可以指定多个Context:
<pre  class="brush:bash">
      jvm.class=org.apache.hadoop.metrics.spi.CompositeContext
      jvm.arity=2  # 指明个数
      jvm.sub1.class=org.apache.hadoop.metrics.file.FileContext
      jvm.fileName=/tmp/jvm_metrics.log
      jvm.sub2.class=org.apache.hadoop.metrics.ganglia.GangliaContext
      jvm.servers=ip-10-250-59-159.ec2.internal:8649
</pre>

</ul>
     
<h3 id="toc_1.2.3">2.3 JMX</h3>
<ol>
<li>
可以通过JMX暴露rpc和dfs的度量信息，但不能暴露jvm和mapred的

<li>
可以通过JConsole查看

<li>
可以设置访问权限

<li>
可以通过第三方工具查看，比如jmxquery, 或Nagios的插件
<pre  class="brush:bash">
      % ./check_jmx -U service:jmx:rmi:///jndi/rmi://namenode-host:8004/jmxrmi -O \
      hadoop:service=NameNode,name=FSNamesystemState -A UnderReplicatedBlocks \
      -w 100 -c 1000 -username monitorRole -password secret
      JMX OK - UnderReplicatedBlocks is 0
</pre>

<li>
提供的MBeans:

</ol>
<table>
<tr>
<th>
MBean class
</th>
<th>
Daemons
</th>
<th>
Metrics
</th>
</tr>
<tr>
<td>
MBNameNodeActivityMBean
</td>
<td>
Namenode
</td>
<td>
Namenode activity metrics, such as the number of create file operations
</td>
</tr>
<tr>
<td>
MBFSNamesystemMBean
</td>
<td>
Namenode
</td>
<td>
Namenode status metrics, such as the number of connected datanodes
</td>
</tr>
<tr>
<td>
MBDataNodeActivityMBean
</td>
<td>
Datanode
</td>
<td>
Datanode activity metrics, such as the number of bytes read
</td>
</tr>
<tr>
<td>
MBFSDatasetMBean
</td>
<td>
Datanode
</td>
<td>
Datanode storage metrics, such as capacity and free storage space
</td>
</tr>
<tr>
<td>
MBRpcActivityMBean
</td>
<td>
All daemons that use RPC: namenode, datanode, jobtracker, and tasktracker
</td>
<td>
RPC statistics, such as average processing time
</td>
</tr>
</table>

<h2 id="toc_1.3">3 维护</h2>

<h3 id="toc_1.3.1">3.1 日常维护</h3>
<h4 id="toc_1.3.1.1">3.1.1 元数据备份 </h4>
<ol>
<li>
namenode的元数据应该备份

<li>
应该保持多个备份：一小时的，一天的，一周的，一月的

<li>
通常的做法是启一个脚本定时备份secondary namenode的 previous.checkpoint的文件夹

<li>
检查血仇是否正常：启一个本地namenode进程，看能否正常加载到内存中

</ol>
 
<h4 id="toc_1.3.1.2">3.1.2 数据备份</h4>
<ol>
<li>
HDFS中的数据也有丢失的可能

<li>
数据需要备份

<li>
备份哪些数据，通常是那些不可重新产生的

<li>
还可以对用户目录容量进行限制

<li>
工具distcp，可以将数据从一个集群拷到另一个集群

</ol>
 
<h4 id="toc_1.3.1.3">3.1.3 文件系统备份</h4>
<ul>
<li>
使用fsck

</ul>

<h4 id="toc_1.3.1.4">3.1.4 文件系统Balancer</h4>
<ul>
<li>
使用balancer

</ul>

<h3 id="toc_1.3.2">3.2 添加或移除结点 </h3>
<p>
因扩容增加结点，因故障移除结点。
</p>

<h4 id="toc_1.3.2.1">3.2.1 添加新结点 </h4>
<ol>
<li>
配置hdfs-site.xml指向 namenode

<li>
配置mapred-site.xml指向jobtracker

<li>
启动datanode与jobtracker守护进程

</ol>
 
<p>
<strong>集群中的机器应该是经过申核的:</strong>
</p>
<ol>
<li>
不能随便一台机器都可以加入集群

<li>
如果这台机器不可靠，数据容易丢失

<li>
通过dfs.hosts控制可以连接namenode的结点

<li>
通过mapred.hosts控制可以连接jobtracker的结点

<li>
这两种文件可以叫做include文件

</ol>
 
<p>
<strong>dfs.hosts,mapred.hosts与slave文件的区别 :</strong>
</p>
<ol>
<li>
*.hosts文件控制能连接主结点的机器，也就是说明结点的合法性

<li>
slaves文件用于进行集群操作时，在哪些机器上进行操作

</ol>
 
<p>
<strong>操作步骤:</strong>
</p>
<ol>
<li>
Add the network addresses of the new nodes to the include file(dfs.hosts mapred.hosts).

<li>
Update the namenode with the new set of permitted datanodes using this command:
<pre  calss="brush:bash">
    % hadoop dfsadmin -refreshNodes
</pre>

<li>
Update the jobtracker with the new set of permitted tasktrackers using:
<pre  calss="brush:bash">
      % hadoop mradmin -refreshNodes
</pre>

<li>
Update the slaves file with the new nodes, so that they are included in future operations performed by the Hadoop control scripts.

<li>
Start the new datanodes and tasktrackers.

<li>
Check that the new datanodes and tasktrackers appear in the web UI.

</ol>
 
<h4 id="toc_1.3.2.2">3.2.2 移除老结点 </h4>
<ol>
<li>
当一次性关闭不同机架上多个datanode时，很可能丢失数据

<li>
所以如果想要移除一台datanode时，应该先告知namenode，在datanode停机前，将数据复制到其他datanode

</ol>

<p>
如果想要移除一个结点，可以将该文件放在exclude文件中:
</p>
<ul>
<li>
hdfs对应dfs.hosts.exclude

<li>
mapreduce对应mapred.hosts.exclude

</ul>

<p>
一个tacktracker是否允许连接jobtracker
</p>
<ol>
<li>
出现在include文件中，且不能出现在exclude文件中

<li>
include文件为空，意味着所有结点都在include中

</ol>

<p>
一个datanode能否连接namenode
</p>
<ol>
<li>
同时出现在include文件和exclude文件中，可以连接，但很快会被解除委任

</ol>


<p>
 HDFS include and exclude file precedence:
<table>
<tr>
<td>
Node appears in include file
</td>
<td>
Node appears in exclude file
</td>
<td>
Interpretation
</td>
</tr>
<tr>
<td>
No
</td>
<td>
No
</td>
<td>
Node may not connect.
</td>
</tr>
<tr>
<td>
No
</td>
<td>
Yes
</td>
<td>
Node may not connect.
</td>
</tr>
<tr>
<td>
Yes
</td>
<td>
No
</td>
<td>
Node may connect.
</td>
</tr>
<tr>
<td>
Yes
</td>
<td>
Yes
</td>
<td>
Node may connect and will be decommissioned
</td>
</tr>
</table>
</p>

<p>
从集群中移除一个结点：
</p>
<ol>
<li>
Add the network addresses of the nodes to be decommissioned to the exclude file.  Do not update the include file at this point.

<li>
Update the namenode with the new set of permitted datanodes, using this command:
<pre class="brush:bash">
    % hadoop dfsadmin -refreshNodes
</pre>

<li>
Update the jobtracker with the new set of permitted tasktrackers using:
<pre class="brush:bash">
     % hadoop mradmin -refreshNodes
</pre>

<li>
Go to the web UI and check whether the admin state has changed to “Decommission In Progress” for the datanodes being decommissioned. They will start copying their blocks to other datanodes in the cluster.

<li>
When all the datanodes report their state as “Decommissioned,” all the blocks have been replicated. Shut down the decommissioned nodes.

<li>
Remove the nodes from the include file, and run:
<pre class="brush:bash">
     % hadoop dfsadmin -refreshNodes
     % hadoop mradmin -refreshNodes
</pre>

</ol>
<p>
7. Remove the nodes from the slaves file
</p>

<h3 id="toc_1.3.3">3.3 升级</h3>

<h4 id="toc_1.3.3.1">3.3.1 HDFS 数据与元数据升级</h4>

<p>
<strong>开始升级:</strong>
</p>

<p>
<strong>等待升级完成:</strong>
</p>

<p>
<strong>检查升级:</strong>
</p>

<p>
<strong>回滚升级:</strong>
</p>

<p>
<strong>完成升级:</strong>
</p>

			</div>

			<div id="bottom">
				&copy; 2012 王兴朝
			</div>
		</div>
	<div>
</body>
</html>
